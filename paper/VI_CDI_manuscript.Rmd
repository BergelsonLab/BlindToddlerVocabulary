---
title             : "The Role of Vision in the Acquisition of Words: Vocabulary Development in Blind Toddlers"
shorttitle        : "Vocabulary Production of Blind Toddlers"


author: 
  - name          : "XXX"
    affiliation   : "1"
    corresponding : yes    
    email         : "XXX"
    address       : "XXX"
  - name          : "XXX"
    affiliation   : "2"
  - name          : "XXX"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "XXX"
  - id            : "2"
    institution   : "XXX"

note: | 
  **Conflicts of Interest**: The authors have no conflicts of interest to report.
  **Funding**: This work was supported by the XXX to XXX and XXX to XXX. 
  
keywords          : "language development; blindness; vocabulary"
wordcount         : "X"

bibliography      : ["VI_CDI_citations.bib"]
nocite            : |
  @campbell2022b

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
latex_engine      : xelatex
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
options(modelsummary_format_numeric_latex = "plain")
# if getting new data from pn-opus, set pull_new_data to TRUE and connect to pn-opus. 
# otherwise, set to FALSE
pull_new_data <- FALSE

library(tidyverse)
library(readr)
library(viridis)
library(lme4)
library(car)
library(papaja)
library(effects)
library(glue)
library(modelsummary)
library(broom.mixed)
library(ggggeffects)
library(ggrepel)
library(ggExtra)

if (pull_new_data == TRUE)
{source("./paper/VI_CDI_preprocessing.R")} else
{VIHI_CDI <- read.csv("./data/CDI/Derived/VIHI_CDI.csv")
VITD_vocabmatches_wordlevel <- read.csv("./data/CDI/Derived/VITD_vocabmatches_wordlevel.csv")
VITD_vocabmatches_wordlevel_single <- read.csv("./data/CDI/Derived/VITD_vocabmatches_wordlevel_single.csv")
wordbank_dict <- read.csv("./data/Norms/wordbank_dict_with_norms.csv") %>%
  mutate(visualornot = as.factor(case_when(Dominant.perceptual=="Visual" ~ "visual",
                                                                 TRUE ~ "not_visual")))}
vocabcomp_details <- read.csv("./data/demographics/vocabcomp_details.csv")
exclusivity_model <- readRDS("./data/models/exclusivity_model.rds")
exclusivity_model_summary <-readRDS("./data/models/exclusivity_model_summary.rds")
perceptualstrength_model <- readRDS("./data/models/perceptualstrength_model.rds")
perceptualstrength_model_summary <- readRDS("./data/models/perceptualstrength_model_summary.rds")

VIHI_CDI_single <- VIHI_CDI  %>% 
  arrange(-WordsProduced) %>%
  distinct(ParticipantNumber, .keep_all = TRUE)

source("./paper/VI_CDI_figures.R")

```

```{r helper-functions}
extract_profile_p <- function(test) {printp(test[["profile.test"]][["Ho: Profiles are parallel"]][["p.value"]][[1]],add_equals=TRUE)}
extract_profile_F <- function(test) {test[["profile.test"]][["Ho: Profiles are parallel"]][["Approx.F"]][[1]]}

details <- function(column, round=2){
  VIHI_CDI %>%
  summarise(min = min(column, na.rm=TRUE),
            max = max(column, na.rm = TRUE),
            mean = round(mean(column,na.rm=TRUE),round),
            sd = round(sd(column, na.rm=TRUE),round),
            )
}
```
# Abstract

What is vision's role in driving early word production? To answer this, we assessed parent-report vocabulary questionnaires administered to congenitally blind children (N = 40, Mean age = 24mo.(R: 7-57mo.)) and compared the size and contents of their productive vocabulary to those of a large normative sample of sighted children (N=`r VIHI_CDI %>% distinct(Wordbank_n) %>% sum()`). We found that on average, blind children showed a roughly half-year vocabulary delay relative to sighted children, amid considerable variability. However, the content of blind and sighted children's vocabulary was statistically indistinguishable in word length, part of speech, semantic category, concreteness, interactiveness, and perceptual modality. At a finer-grained level, we also found that words' perceptual properties intersect with children's perceptual abilities. Our findings suggest that while an absence of visual input may initially make vocabulary development more difficult, the content of the early productive vocabulary is largely resilient to differences in perceptual access. 

# Statement of Relevance

Early word learning is often explained as children connecting words with what they see through object-referent co-occurrence and joint attention. And yet, congenitally blind individuals learn language without vision, suggesting that either vision is not necessary for word learning or that it proceeds differently for blind versus sighted individuals. Looking to the earliest stages of word production, we find evidence that young blind children are modestly delayed in word production but also have vocabularies that are highly similar to sighted toddlers' in sound, meaning, and grammar, and even in "visualness" (though blind children are more likely to produce multimodal words than sighted peers). Consistent with prior work, this suggests that language input itself is key to supporting early language learning. These results have important implications both for supporting blind individuals in particular and for our broader understanding of how sensory and linguistic signals are integrated in language development in all learners.

<!-- 2000 words for intro, discussion, footnotes, acknowledgements, appendices, currently at 1974 on 12/21 -->

# Introduction 

Descriptions of early word learning often invoke visual scenes: a messy living room, a rabbit jumping across a trail. At some level, word learners are thought to take the linguistic input, deduce referents in a visual sea of possibilities, and connect this input to intended meaning. How do young learners do this? Some propose they look for visually salient objects [@yu2012]; others suggest central roles for following speakers' gaze or intent [@brooks2008; @tomasello2003]. These strategies could help constrain referent possibilities given novel word and ambiguous visual input, but such approaches do not work for all words, let alone all learners. 

If visual input is integral to word learning, then its absence should lead to pronounced differences in language abilities. However, blind adults perform comparably to sighted adults on many language tasks, and on some tasks, demonstrate faster language processing than sighted adults [@bottini2022; @roder2003; @loiotile2020]. But are these equivalencies or advantages present in the earliest stages of language development, or do they emerge over time? One way to tackle this question is to study vocabulary development in congenitally blind children. We ask: does a radically different experience of perceiving the world leads to differences in how we begin to learn words? 

## Potential Challenges for the Blind Learner. 

Though blind adults are skilled language users, their early lexicon (in terms of vocabulary size and composition) remains unclear. Before returning to this, we discuss several social and motor supports of early language development for sighted children that are absent or delayed in blind children.

The ability to reach for, grasp, and manipulate objects of interest has been argued to support word learning. For instance, words with easily manipulable referents are more frequent in children's early productive vocabulary than non-manipulable ones [e.g. cup vs. table, @nelson1973]. Additionally, children's object manipulation may highlight children's attentional focus for parents, eliciting more object naming [@west2017; @west1978; @tamis-lemonda2013; @luo2016]. Relatedly, held objects dominate infants' visual field [@yu2012]. Taken together, these lines of work suggest infants' object manipulation may facilitate word learning.

In blind children, grasping and reaching are delayed [@norris1957; @fraiberg1977; @perez-pereira1994]. While sighted children reach towards a seen object at around 4--6 months [@vonhofsten1989], a parallel ability, reaching towards an object making noise, does not emerge in blind infants until around 8 months, similar to sighted children's timeline for hand-ear coordination [@fraiberg1977]. If reaching for and manipulating objects cues parents to their infant's interest, then blind infants may not receive language input tailored to the locus of their attention, which in turn may influence early word learning.

Social interaction provides another support for children's early word learning. Parents often talk about what they or their child are looking at [@yurovsky2013; @tomasello2003]. In turn, following speakers' gaze may help children deduce communicative intent [@carpenter1998; @brooks2008; @meltzoff2009]. In sighted infants, gaze-following is linked with later vocabulary size [@brooks2008]; in blind infants, gaze is not an accessible word meaning cue.

Likewise, pointing is linked with children’s language ability [@moore2019; @colonnesi2010], perhaps because it too directs a conversation partner’s attention. Sighted infants shift their gaze to the direction of the point reliably by around  10--12 months of age [@carpenter1998] and begin pointing themselves at around the same age [@moore2019]. Pointing is argued to support word learning by serving as a naming "request" [@lucca2019]; by 18 months, labels given after infants point are better learned [@lucca2018]. By contrast, in naturalistic settings, 14--24-month-old blind infants rarely point, instead gesturing with an open palm towards proximal objects [@iverson2000], though the link between this behavior and word learning has not been empirically tested.

Reaching, gaze-following, and pointing are useful cues for establishing joint attention, wherein two individuals are simultaneously focused on each other and an object or event. Joint attention may provide referentially transparent language input, which can facilitate word learning [@tomasello1986]. For blind children however, joint attention is often delayed relative to sighted peers [@perez-pereira1999; @bigelow2003], [even more so for those no residual vision, @dale2014]. This suggests that any word learning benefits of joint attention too may be reduced or delayed for blind children.  

## Vocabulary Development in Blind Children. 

The potential challenges for blind learners enumerated above are intended to showcase the various ways that vision might influence early word learning. If the highlighted skills are indeed critical, we would expect profound language deficits in this population. However, prior work on productive vocabulary development in blind children is inconclusive. Some research finds that blind infants learn words on roughly the same timeline as sighted infants [@landau1985; @wilson1947]; others find delays in first-word production [@brambring2007; @fraiberg1977; @iverson2000; @moore1994; @mulford1988]. The existence and extent of vocabulary delays may of course be influenced by a host of other factors, such as severity of the vision diagnosis, etiology, comorbid diagnoses, etc. [@greenaway2017]. Understanding which blind children may be at particular risk for language deficits or delays remains an important clinical goal.

###  Vocabulary Composition 

The composition of blind children’s first words has been reported as largely similar to that of sighted children. Like English-learning sighted children, English-learning blind children’s first words include a large proportion of nouns [@andersen1984; @bigelow1986; @dunlea1989; @landau1985]. Some studies have found that blind children may have a weaker noun bias [@mcconachie1994; @mulford1988; @norgate1997], which may be due to fewer “point-and-look” learning episodes relative to sighted children [@norgate1997]; others report fewer words for distal objects [e.g. outdoor objects and animals, @bigelow1987a]. These differences in vocabulary composition are small in magnitude and inconsistent across the literature. More strikingly, despite lacking visual access, blind children preschool age and up have been reported are reported to use visual terms like "red" [@landau1985; @harley1963; @demott1972]. 

While existing research on vocabulary development in blind children provides a valuable foundation, each of the studies cited above is based on a limited sample size, typically N<10. This stems from the challenges of sampling young blind children without additional cognitive deficits; congenital blindness often occurs as part of syndromes with wide-ranging symptoms [e.g., @garcia-filion2013]. Expanding this work is an important goal, both for improving early intervention services for blind children, as well as better understanding how visual perception contributes to word learning more broadly. In what follows, we explore the role of vision in word learning using a standardized vocabulary measure administered to `r VIHI_CDI %>% distinct(ParticipantNumber) %>% nrow()` blind children. We ask whether blind children have productive vocabulary differences relative to their sighted peers, both in quantity (how many words they produce), and composition, (which words they produce).

<!--1065 words in intro 12/21-->

# Methods

```{r sample-characteristics}
n_admins <- VIHI_CDI %>% group_by(ParticipantNumber) %>% summarise(N= n()) 
age_comp <- wilcox.test(vocabcomp_details$age ~ vocabcomp_details$group)
```

Approximately 1/10,000 children is born with severe to profound visual impairment [@gilbert2003]. Given the low incidence of this condition, our sample includes `r VIHI_CDI %>% distinct(ParticipantNumber) %>% nrow()` young, congenitally blind children (`r min(VIHI_CDI$age_months)`--`r max(VIHI_CDI$age_months)` months, M: `r round(mean(VIHI_CDI$age_months, na.rm=TRUE), 2)` (`r round(sd(VIHI_CDI$age_months, na.rm=TRUE), 2)`) months). To focus specifically on the role of vision in language development, children met inclusion criteria if they (1) were exposed to >75% English at home, (2) had *no more than minimal light perception* in both eyes, (3) had no co-occurring cognitive or developmental diagnoses, and (4) had no history of frequent ear infections or hearing loss; see Table \@ref(tab:diagnosis-table) for vision diagnosis specifics. Data from 3 participants were collected but excluded due to bilingualism (N=2), hearing loss (N=2), and/or co-occurring cognitive or developmental diagnoses (N=1). Participants were recruited in the United States and Canada via pediatric ophthalmology clinics, early intervention and preschool programs for blind children, social media, and word of mouth. Many participants contributed data at multiple timepoints, for a total of N=`r VIHI_CDI %>% nrow()` total datapoints (`r min(n_admins$N)`--`r max(n_admins$N)` per child, M: `r mean(n_admins$N, na.rm=TRUE)`); to avoid overrepresenting participants, we use only data from the oldest timepoint for analyses, with a few exceptions, noted below. Data from `r VIHI_CDI %>% filter(Source=="Herrera") %>% distinct(ParticipantNumber) %>% nrow()` participants were originally described in @herrera2015. Participant demographics are available in Table \@ref(tab:demographics-table).

```{r diagnosis-table}
Nunsure<- VIHI_CDI %>% filter(is.na(SevereorProfound)) %>% nrow()

VIHI_CDI_single %>% 
  select(c(SevereorProfound, VisionDiagnosisStandardized))%>%
  mutate(SevereorProfound = case_when(SevereorProfound == "SVI" ~ "Severe",
                                      SevereorProfound == "PVI" ~ "Profound",
                                      TRUE ~ "not reported")) %>%
  mutate(VisionDiagnosis = replace_na(VisionDiagnosisStandardized, 'Not specified')) %>%
  dplyr::rename("Severity" = "SevereorProfound",
                "Diagnosis" = "VisionDiagnosis") %>%
  group_by(Diagnosis) %>%
  summarise(Nsevere=sum(Severity=="Severe"),
            Nprofound=sum(Severity=="Profound"),
            Nunsure=sum(Severity=="not reported")) %>%
  mutate(Etiology = case_when(Diagnosis=="Not specified" | 
                                Diagnosis=="Multiple" ~ " ",
                              Diagnosis == "Optic Nerve Hypoplasia" |
                              Diagnosis ==  "CVI"|
                               Diagnosis ==  "Optic Pathway Glioma" ~ "Neural",
                              TRUE ~ "Eye")) %>%
    arrange(-(Nsevere+Nprofound+Nunsure))  %>%
kableExtra::kable(caption = 'Severity of visual impairment and vision diagnoses for each child in the sample.', col.names = c("Diagnosis", "N severe", "N profound", "N severity unspecified","Etiology")) %>%
kableExtra::kable_styling(latex_options="HOLD_position")

```

```{r demographics-table}

agedetails <- details(VIHI_CDI$age_months)
receptiveCDIdetails <- details(VIHI_CDI$WordsUnderstood)
productiveCDIdetails<- details(VIHI_CDI$WordsProduced)



tribble(~ Variable, ~ `Range and Mean, or Ns`,
        "Age (months)", 
        glue('{agedetails$min}-{agedetails$max} months (mean (SD): {agedetails$mean} ({agedetails$sd}))'),
        "Receptive Vocabulary* (CDI)", 
        glue('{receptiveCDIdetails$min}-{receptiveCDIdetails$max} words (mean (SD): {receptiveCDIdetails$mean} ({receptiveCDIdetails$sd}))'),
        "Productive Vocabulary (CDI)", 
        glue('{productiveCDIdetails$min}-{productiveCDIdetails$max} words (mean (SD): {productiveCDIdetails$mean} ({productiveCDIdetails$sd}))'),
        'CDI Version', 
        glue('Words and Gestures ({nrow(VIHI_CDI %>% filter(Version=="WG"))}); Words and Sentences ({nrow(VIHI_CDI %>% filter(Version=="WS"))})'),
        "Gender", 
        glue('Female ({nrow(VIHI_CDI_single %>% filter(sex=="Female"))}); Male ({nrow(VIHI_CDI_single %>% filter(sex=="Male"))})'),
        "Maternal Education", 
        glue('High School ({nrow(VIHI_CDI_single %>% filter(mom_ed=="Secondary"))}); Some College ({nrow(VIHI_CDI_single %>% filter(mom_ed=="Some College"))}), Bachelors degree ({nrow(VIHI_CDI_single  %>% filter(mom_ed=="College"))}), Graduate degree ({nrow(VIHI_CDI_single  %>% filter(mom_ed=="Graduate"))})'))  %>% 
  kableExtra::kable(caption = glue('Demographic characteristics of the {nrow(VIHI_CDI %>% distinct(ParticipantNumber, .keep_all=TRUE))} participants in the study')) %>%
  kableExtra::add_footnote("Receptive vocabulary scores only measured on Words and Gestures version of CDI; all Words and Sentences administrations excluded from these values.", notation="symbol",threeparttable = TRUE) %>%
  kableExtra::column_spec(2, width = "4in") %>%
  kableExtra::kable_styling(latex_options="HOLD_position")
```

Parents of each child in our sample completed the MacArthur-Bates Communicative Development Inventory (CDI). The CDI is a parent-report instrument predominantly used to assess children’s productive/receptive vocabulary alongside a few items regarding other aspects of early language; we focus on the vocabulary data here. On the Words and Gestures version of the form (WG; normed for 8–18-month-olds), parents indicate whether their child understands and/or produces each of the 398 vocabulary items. On the Words and Sentences version (WS; normed for 16–30-month-olds), parents indicate whether their child produces each of the 680 vocabulary items. 

Normative data for the CDI is available from English and many other languages on WordBank [e.g., @frank2017], an open database of CDI data. While the CDI has not been validated for blind children, it has been used successfully in other special populations, such as Deaf/Hard-of-Hearing children [@thal2007], late talkers [@heilmann2005], and children with Down syndrome [@miller1995]. Critically, in many of these populations, the CDI production measure has been validated for “off-label” usage above the chronological age for which the CDI has been normed for typically-developing children [@thal2007; @heilmann2005; @miller1995]. 

# Results

## Analysis Plan

Our results are organized around answering the two questions set out above: do blind and sighted children differ in how many words they say at a given age, and do they differ in the composition of those vocabularies. To address the first question we compared blind children's vocabulary on the CDI relative to norms derived from sighted children of the same age. We then considered a variety of child level characteristics to get a better understanding of what may contribute to the overall delay we observe, as well as an analysis of delay size with age. For these analyses we used logistic regression curves, Wilcoxon Tests, and linear regression, as relevant. To address the second question, we matched for vocabulary size and compared blind and sighted children's vocabulary composition across a range of factors: word length, part of speech, semantic category, concreteness, interactiveness, and perceptual modality (details below). For these analyses we used Bonferroni-corrected Wilcoxon Tests and logistic regressions. Previewing the results to this question, we found very consistent vocabulary composition across our blind and sighted groups. We describe the findings in full detail below, and provide the data and code used to generate this paper on OSF [(link)](https://osf.io/uw6zm/?view_only=fdee466143f64d678d7f9d87b23ec566). These analyses were not preregistered.

## Do blind children and sighted children show similar word production trajectories?

To analyze whether blind children produce a similar *quantity* of words to their sighted peers, we used a large set of vocabulary production data from Wordbank. The normative dataset contains data from `r VIHI_CDI %>% distinct(Wordbank_n) %>% sum()` children learning American English (downloaded `r VIHI_CDI %>% distinct(Wordbank_norms_date)` from Wordbank [(link)](http://wordbank.stanford.edu/data?name=vocab_norms "Wordbank Vocabulary Norms")). As noted above, the two CDI forms differ in how many vocabulary items they contain. To take this into account, we established the difference (in months) between the child’s chronological age and their predicted age based on their productive vocabulary, derived from the WordBank norms [@frank2017], rather than using the raw number of words checked off on the instrument. We call this derived variable, measured in months, *vocabulary difference*.

Following the procedure in Campbell & Bergelson (2022), to compute a child's predicted age from their vocabulary score, we used the Wordbank's 50th percentile for productive vocabulary for sighted infants [@frank2017] to create two binary logistic growth curves (for the WG and WS versions of the CDI). For each child, we took their productive vocabulary score, as reported on the CDI. We then divided the number of words produced by the number of possible words on the instrument (WG or WS), to give us the proportion of words produced. We used this proportion in an inverse prediction from the binary logistic regression curves to generate a predicted age. That is, for each possible CDI score, the growth curve provided the age that the score would be achieved for the 50th percentile trajectory. Finally, we subtracted the predicted age from each child's chronological age to calculate their vocabulary delay or advantage. However, for children producing 0 words (N=`r VIHI_CDI %>% filter(WordsProduced==0) %>% distinct(ParticipantNumber) %>% nrow()`), this approach is not appropriate due to the long tails on the growth curves. Thus, for this subset of children, we took the x-intercept from Wordbank (8 months), and subtracted that value from the child's chronological age to get their months difference. 

Applying this approach to each child, we observe wide variability; vocabulary differences for blind children range from `r round(abs(min(VIHI_CDI$diff_age_from_expected, na.rm=TRUE)), 1)` months ahead to `r round(abs(max(VIHI_CDI$diff_age_from_expected, na.rm=TRUE)), 1)` months behind; see Figure \@ref(fig:density-plot). A Wilcoxon 1-sample test on the data reveals that blind children's vocabulary difference significantly differed from 0 (0 would indicate no difference in vocabulary distribution of blind children from the 50th percentile of sighted children). Blind children had a mean vocabulary delay of `r round(abs(mean(VIHI_CDI$diff_age_from_expected, na.rm=TRUE)),1)` months (SD: `r round(abs(sd(VIHI_CDI$diff_age_from_expected, na.rm=TRUE)),1)`). That said, `r round((VIHI_CDI %>% filter(diff_age_from_expected < 0) %>% nrow())/(VIHI_CDI %>% nrow()) *100, 1)`% of our sample was ahead of the sighted 50th percentile norm. That is, rather than all of the blind children being behind the sighted 50th percentile (as would be the case if missing vision led to a pervasive, consistent delay in early word production), or blind children being indistinguishable from sighted peers in vocabulary size (which would have been manifest as roughly 50% of blind children with delayed and 50% with advanced vocabulary) we see an intermediary effect: roughly half a year delay on average, with about 20% of the sample showing a vocabulary advantage over the average for sighted peers.

```{r density-plot, fig.cap="Histogram with overlaid density plot of blind sample's vocabulary difference relative to Wordbank norms. Positive values indicate delay, while negative values represent scores that are ahead of the 50th percentile curve from sighted participants."}
density_plot
```

### Exploring Variability
```{r splitting-tests, fig.cap="Density plot dividing the sample by gender (A), severity (B), and etiology (C).", fig.height=6, fig.width=5}

# Gender
gender_split_info <- VIHI_CDI_single %>% 
  group_by(sex) %>%
  summarise(N = n(),
            MeanDelay = mean(diff_age_from_expected, na.rm=TRUE),
            sdDelay = sd(diff_age_from_expected, na.rm=TRUE))
gender_diffs <- wilcox.test(VIHI_CDI_single$diff_age_from_expected ~ VIHI_CDI_single$sex, 
                        alternative = "two.sided",
                        exact = NULL)

# Severity
severity_split_info <- VIHI_CDI_single %>% 
  group_by(SevereorProfound) %>%
  summarise(N = n(),
            MeanDelay = mean(diff_age_from_expected, na.rm=TRUE),
            sdDelay = sd(diff_age_from_expected, na.rm=TRUE))

severity_diffs <- wilcox.test(VIHI_CDI$diff_age_from_expected ~ VIHI_CDI$SevereorProfound, 
                        alternative = "two.sided",
                        exact = NULL)

# Etiology
etiology_diffs <- wilcox.test((VIHI_CDI %>% filter(grepl("Hypoplasia|CVI",VisionDiagnosisStandardized)))$diff_age_from_expected, (VIHI_CDI %>% filter(!grepl("Hypoplasia|CVI",VisionDiagnosisStandardized)))$diff_age_from_expected, 
                          alternative = "two.sided",
                          exact = NULL)
etiology_split_info <- VIHI_CDI_single %>%
  group_by(Etiology) %>%
  summarise(N = n(),
            MeanDelay = mean(diff_age_from_expected, na.rm=TRUE),
            sdDelay = sd(diff_age_from_expected, na.rm=TRUE))

cowplot::plot_grid(gender_diff_plot, severity_diff_plot, etiology_diff_plot, ncol=1, labels = c("A", "B","C")) 
```

To better understand the wide range of vocabulary outcomes, we next divided our blind sample along several child-level characteristics and compared the distribution of vocabulary differences via Wilcoxon tests; see Figure \@ref(fig:splitting-tests). Splitting the sample by gender (N~male~=`r gender_split_info$N[2]`, N~female~=`r gender_split_info$N[1]`), we do not observe significant gender differences (Mean~male~ delay = `r gender_split_info$MeanDelay[2]` months vs.  Mean~female~ delay = `r gender_split_info$MeanDelay[1]` months; W = `r round(gender_diffs$statistic, 3)`, *p* = `r printp(gender_diffs$p.value)`). We also did not observe differences based on severity of vision impairment within the severe-to-profound range of vision loss in our sample: children with severe vision impairment (some light perception; N~severe~=`r severity_split_info$N[2]`; Mean~severe~ delay = `r severity_split_info$MeanDelay[2]` months) had a similar size vocabulary delay to children with profound vision impairment (no light perception, N~profound~=`r severity_split_info$N[1]`; Mean~profound~ delay =`r severity_split_info$MeanDelay[1]` months; W = `r round(severity_diffs$statistic, 3)`, *p* = `r printp(severity_diffs$p.value)`). Lastly, we divided by etiology and found no significant difference (W = `r round(etiology_diffs$statistic, 3)`, *p* = `r printp(etiology_diffs$p.value)`): neural diagnoses (optic nerve hypoplasia or CVI; N~neural~=`r etiology_split_info$N[2]`; Mean~neural~ delay =`r etiology_split_info$MeanDelay[2]` months) vs. eye diagnoses (N~eye~=`r etiology_split_info$N[1]`; Mean~eye~ delay =`r etiology_split_info$MeanDelay[1]` months). We note that there was no particular selection for these dimensions within our eligibility criteria, and thus some of these comparisons are on unbalanced samples. 

### Does the delay lessen across age?

```{r over-time}
summary_age_delay <- summary(age_delay)
age_delay_test <- Anova(age_delay)

```

We next measured whether the delay in vocabulary stayed constant across age. We conducted a linear mixed effect model with a fixed effect of age and a random effect of participant, given that for `r VIHI_CDI %>% group_by(ParticipantNumber) %>% slice(2) %>% nrow()` participants, we have longitudinal administrations of the CDI. If delay were constant, we would not expect it to change as children age. Instead, we found a significant effect of age, such that for each month increase in age, vocabulary delay increased by `r summary_age_delay$coefficients[[2]] * 4.34524` weeks (F(`r age_delay_test$Df`) = `r age_delay_test$Chisq`, *p* `r printp(age_delay_test$'Pr(>Chisq)',add_equals=TRUE)`); see Figure \@ref(fig:longitudinal-plot).
<!-- note to self: 4.34524 = weeks in a month -->

```{r longitudinal-plot, fig.cap="Vocabulary delay in blind children plotted as a function of age. Raw data are plotted in color. Each dot represents one CDI administration, with lines connecting datapoints from the same participant. Black dashed line represents the model estimate with standard error: Vocabulary Delay ~ Age + (1|Participant)."}
longitudinal_plot
```

## Do blind children and sighted children have a similar vocabulary composition?
We next investigated the composition of blind children's early words. Given the disparities between the vocabulary production of blind vs. sighted children, we compared blind participants to a vocabulary-size-matched group of sighted children from Wordbank. We matched each blind child in our sample to a unique sighted participant from Wordbank. Sighted matches were selected to have the same number of words produced on the same form (WG vs. WS) and to be as close as possible in age to the blind child; beyond this matching they were selected at random. Consequently, our samples for the vocabulary composition analysis are equivalent in vocabulary production but differ slightly in age (sighted sample on average `r  round(mean((vocabcomp_details %>% filter(group=="VI"))$age) - mean((vocabcomp_details %>% filter(group=="TD"))$age),1)` months younger, *p* `r printp(age_comp$p.value, add_equals = TRUE)` by Wilcoxon test); see Figure \@ref(fig:vocab-match-demo).

```{r vocab-match-demo, fig.cap="Violin plots for age (left) and vocabulary size (right) for blind participants and their vocabulary size matched sighted peers, from Wordbank. Each dot represents one participant. Given that participants are matched exactly on vocabulary, the vocabulary scores on the right panel are identical for blind and sighted participants."}


cowplot::plot_grid(agecomp_plot, vocabcomp_plot)

```

We then compared the words that blind and sighted children with equivalent vocabulary size produced. Children producing 0 words were excluded from this analysis (N=`r VIHI_CDI_single %>% filter(WordsProduced==0) %>% nrow()`). We compared vocabularies along six dimensions: word length, part of speech, semantic category, concreteness, child-body-object interaction rating (interactiveness), and perceptual modality, operationalized below.

**Word length** was computed as number of syllables in each word. **Part of speech** (adjectives, adverbs, function words, interjections, nouns, onomatopoeia, and verbs) and **semantic category\footnote{Not all categories from Words and Sentences appear on Words and Gestures. Additionally, some of the "semantic categories" could also be considered parts of speech. The word-level breakdown of each of these categories can be found on our OSF page.}** (action words, animals, dody parts, clothing, connecting words, descriptive words, food and drink, furniture and rooms, games and routines, helping verbs, household, locations, outside, people, places, pronouns, quantifiers, question words, sounds, time words, toys, and vehicles) subdivisions were taken from the categories on the CDI. For **concreteness**, we used the Brysbaert Concreteness ratings [@brysbaert2014], which asked sighted adult participants to rate words from 1 (Abstract - language based) to 5 (Concrete - experience based); `r wordbank_dict %>% distinct(Word, .keep_all=TRUE) %>% filter(is.na(Conc.M)) %>% nrow()` words were excluded from this analysis due to not having a concreteness rating. **Interactiveness** ratings were taken from the child-body-object interactiveness ratings from @muraki2022. These are 1-7 ratings by parents of school-aged children of how easily children can physically interact with each of the words. `r wordbank_dict %>% distinct(Word, .keep_all=TRUE) %>% filter(is.na(CBOI_Mean)) %>% nrow()` words were excluded from this analysis due to not having a rating. Lastly, **perceptual modality** was determined by the Lancaster Sensorimotor Norms [@lynott2020], taken from a large sample of sighted adults, who were asked to rate: "To what extent do you experience WORD by [hearing, smelling, tasting, seeing, etc.]?". Each word was rated 0-5 for each modality, and the modality which received the highest rating is used here for the perceptual modality of the word.

To compare words across each of these dimensions, we used profile analyses and Wilcoxon tests, depending on the type of variable. For semantic category, perceptual modality, and part of speech, we compared counts of each word type across groups using profile analysis. For concreteness and word length, we ran Wilcoxon tests. Given that we conducted multiple comparisons (five total, one per dimension), the Bonferroni-corrected threshold for significance is `r printnum(.05/6, digits=4)`. 


```{r word-length}

test_mean_lengths <- wilcox.test(mean_length$Syllables ~ mean_length$group)
Z_meanlengths<-round(qnorm(test_mean_lengths$p.value/2),2)


```

```{r pos}
pos_by_group <- profileR::pbg(data=VITD_pos_Ns[,c(3:9)], group=VITD_pos_Ns$group, profile.plot = FALSE, original.names = TRUE)
```

```{r semantic}
category_by_group <- profileR::pbg(data=VITD_category_Ns[,3:24], group=VITD_category_Ns$group, profile.plot = FALSE, original.names = TRUE)
```

```{r modality}
dom_modality_by_group <- profileR::pbg(data=VITD_modality_Ns[,c(3,4,5,6,7,8)], group=VITD_modality_Ns$group, profile.plot = FALSE, original.names = TRUE)
```

```{r vocab-comparison, fig.height=7, fig.width=9, fig.cap="Comparisons of blind and sighted children's vocabulary across 6 dimensions. Whiskers represent 95% CIs around the mean. **A**: Mean length (syllables) for sighted vs. blind participants. **B**: Mean N of words produced by blind and sighted children from each part of speech on CDI.  **C**: Mean N of words produced by blind and sighted children from each semantic category on CDI. **D**: Mean concreteness rating 1 (abstract) -- 5 (concrete) for sighted vs. blind participants. **E**: Mean child-body-object interaction rating 1 (not interactive) -- 7 (highly interactive) for sighted vs. blind participants. **F**: Mean N of words produced by blind and sighted children for each perceptual modality (modality with highest perceptual rating on Lancaster Sensorimotor Norms). Note the truncated y axis for D and E."}

first_col <- cowplot::plot_grid(word_length_plot, concreteness_plot, CBOI_plot, ncol = 1, labels=c("A","D","E"))
second_col <- cowplot::plot_grid(pos_plot, category_plot, modality_plot, ncol = 1, labels = c("B","C", "F"), rel_heights = c(1,1.3,1.1))
cowplot::plot_grid(first_col, second_col, cols = 2, rel_widths = c(1,4))
```

None of the comparisons reached the *p*<`r .05/6` threshold for significance. Blind and sighted children's early vocabularies did not significantly differ in word length (W =`r test_mean_lengths$statistic`, *Z* = `r Z_meanlengths`, *p* `r printp(test_mean_lengths$p.value, add_equals=TRUE)`), part of speech (F = `r extract_profile_F(pos_by_group)`, *p* `r extract_profile_p(pos_by_group)`), semantic category (F = `r extract_profile_F(category_by_group)`, *p* `r extract_profile_p(category_by_group)`), concreteness (W =`r test_mean_concreteness$statistic`, *Z* = `r Z_meanconcrete`, *p* `r printp(test_mean_concreteness$p.value, add_equals=TRUE)`), interactiveness (W =`r test_mean_CBOI$statistic`, *Z* = `r Z_mean_CBOI`, *p* `r printp(test_mean_CBOI$p.value, add_equals=TRUE)`), or perceptual modality (F = `r extract_profile_F(dom_modality_by_group)`, *p* `r extract_profile_p(dom_modality_by_group)`). See Figure \@ref(fig:vocab-comparison) for vocabulary comparisons. Descriptively, both blind and sighted children's words tended to be short (Means: `r length_summary$Mean[2]` and `r length_summary$Mean[1]` syllables, respectively) and highly concrete (Means: `r concrete_summary$Mean[2]` and `r concrete_summary$Mean[1]` out of 5, respectively). The words that blind and sighted children produced tended to be rated as easy for children to interact with (Means: `r CBOI_summary$Mean[2]` and `r CBOI_summary$Mean[1]` out of 7, respectively). In both groups, nouns were the most common part of speech, and visual words comprised the overwhelming majority of children's early vocabulary.

```{r visualornot, fig.height=6, fig.width=6, fig.cap="Visualization of the significant 3-way interaction between **A** Modality (visual/non-visual), Perceptual Strength (0-5), and Group (blind/sighted) and **B** Modality, Perceptual Exclusivity (0-1), and Group in predicting probability of word production (see text for model details). Y-axis shows the model-predicted probability of word production, with 95% confidence interval; distribution of predicted probability (of individual words) shown in margins. X-axis shows perceptual property (perceptual strength in A, perceptual exclusivity in B); distribution of words' varying ratings shown in margins. **C**: Perceptual properties of visual and non-visual on the CDI -- perceptual strength on the x-axis and perceptual exclusivity on the y-axis. Some individual words are labeled for illustrative purposes."}

 cowplot::plot_grid(model_plots,word_perceptual_properties, ncol=1, rel_heights = c(1,1.5), labels = c("","C"))

```

## How do perceptual characteristics of words affect learnability?

It was somewhat surprising to find such striking parallels in blind and sighted children's vocabulary, particularly the dominance of "visual" words, given that blind children lack visual access to the words' referents. That said, many of these words may be perceptible through other modalities. For example, while "playground" is classified as a visual word on the Lancaster Sensorimotor Norms, playgrounds can also be experienced through touch, sound, smell, or even taste. To explore this further, we next compared blind and sighted children's likelihood of producing visual words (i.e., words whose highest perceptual ratings were visual) and non-visual words (i.e., words whose highest perceptual ratings were auditory, tactile, olfactory, interoceptive, or gustatory), based on the perceptual strength of each word and its perceptual exclusivity. To increase power for this more fine-grained analysis, we include all CDI administrations, rather than just the CDI from the oldest timepoint when multiple timepoints per child were available. Words that did not appear on a child's instrument (e.g., lawnmower does not appear on Words and Gestures) were excluded for those children.

To do this, we constructed two logistic mixed effect models that predicted the log likelihood of a word being produced as a function of the three way interaction between the words' perceptual modality (visual or non-visual)\footnote{Given the large proportion of visual words and relative sparsity of other modalities in children's vocabulary, we grouped auditory, tactile, haptic, interoceptive, olfactory, and gustatory words into a "non-visual" category for the purpose of this analysis.}, group (blind, sighted), and either the word's perceptual strength (highest perceptual strength rating across all modalities, rated 1-5) or the word's perceptual exclusivity (expressed as a proportion from 0-1 calculated as the range of the ratings of all modalities divided by the sum of the ratings of all modalities. 0 = experienced equally in all modalities, 1 = experienced exclusively through a single modality); model formulae are below. Each model also included a random effect of child due to the multiple measures within some participants, as well as a random effect for word given that there is an observation for each word for each participant, and the likelihood of word-level variance being non-random (though not of interest for the present analysis). Thus, we fit two models as follows:  
**Perceptual Strength Model:** $Word\ Production \sim Perceptual\ Strength * Perceptual\ Modality * Group + (1|Participant) + (1|Word)$  
**Perceptual Exclusivity Model:** $Word\ Production \sim Perceptual\ Exclusivity * Perceptual\ Modality * Group + (1|Participant) + (1|Word)$  

For the perceptual strength model (Table \@ref(tab:ps-table)), we found a significant main effect of perceptual strength ($\beta$ = `r perceptualstrength_model_summary$estimate[3]`, *p* `r printp(perceptualstrength_model_summary$p.value[3],add_equals = TRUE)`). Overall, the groups did not differ in likelihood of producing words ($\beta$ = `r perceptualstrength_model_summary$estimate[4]`, *p* `r printp(perceptualstrength_model_summary$p.value[4],add_equals = TRUE)`), and the effect of perceptual strength did not differ by group ($\beta$ = `r perceptualstrength_model_summary$estimate[7]`, *p* `r printp(perceptualstrength_model_summary$p.value[7],add_equals = TRUE)`) or by modality ($\beta$ = `r perceptualstrength_model_summary$estimate[2]`, *p* `r printp(perceptualstrength_model_summary$p.value[2],add_equals = TRUE)`). This pattern of main effects was qualified by a significant interaction between group and modality, such that blind children were significantly less likely to produce visual words than non-visual words ($\beta$ = `r perceptualstrength_model_summary$estimate[6]`, *p* `r printp(perceptualstrength_model_summary$p.value[6],add_equals = TRUE)`). Finally, there was a significant three-way interaction between modality, perceptual strength, and group, such that for sighted children, there was a similar effect of perceptual strength for visual and non-visual words. For blind children however, the effect of perceptual strength was much stronger for non-visual words than visual words ($\beta$ = `r perceptualstrength_model_summary$estimate[8]`, *p* `r printp(perceptualstrength_model_summary$p.value[8],add_equals = TRUE)`). See Figure \@ref(fig:visualornot). 

```{r ps-table, fig.pos='H'}
modelsummary::msummary(list("Perceptual Strength * Modality * Group"=perceptualstrength_model), estimate= c("{estimate} [{conf.low}, {conf.high}]"), statistic = "{printp(p.value)}{stars}", stars = c('*' = .05, '**' = .01, '***' = .001),fmt=list("estimate"=2, conf.low=2, conf.high=2,"fmt"=NULL), shape = term ~ model + statistic, coef_rename = c('visualornotvisual' = 'Modality (visual)', 'Max_strength.perceptual' = 'Perceptual Strength','groupBlind'= 'Group (blind)', 'visualornotvisualMax_strength.perceptual' = 'Modality (visual) × Perceptual Strength','visualornotvisualgroupBlind'  = 'Modality (visual) × Group (blind)','Max_strength.perceptualgroupBlind'  = 'Perceptual Strength × Group (blind)','visualornotvisualMax_strength.perceptualgroupBlind' = 'Modality (visual) × Perceptual Strength × Group (blind)'), gof_map = NA, output="data.frame")  %>%
  select(-1) %>%
  slice(1:(n() - 2))%>%
  kableExtra::kable(
    col.names = c("Variable", "Beta [95% CI]",
                  "p value"), caption = 'Logistic regression estimates for the perceptual exclusivity model (see formula in main text). Reference level for Modality is non-visual, and reference level for Group is sighted. Parentheticals indicate what is being compared to reference level.') %>%
  kableExtra::kable_classic(full_width=FALSE) %>%
  kableExtra::kable_styling(latex_options="HOLD_position")


```

For the perceptual exclusitivy model (Table \@ref(tab:excl-table)), we again found that the groups did not differ in overall likelihood of producing words ($\beta$ = `r exclusivity_model_summary$estimate[4]`, *p* `r printp(exclusivity_model_summary$p.value[4],add_equals = TRUE)`). The main effect of perceptual exclusivity was not significant ($\beta$ = `r exclusivity_model_summary$estimate[3]`, *p* `r printp(exclusivity_model_summary$p.value[3],add_equals = TRUE)`), and did not differ by group ($\beta$ = `r exclusivity_model_summary$estimate[7]`, *p* `r printp(exclusivity_model_summary$p.value[7],add_equals = TRUE)`). Here too, this pattern of main effects was qualified by a significant interaction between group and modality, such that blind children were significantly less likely to produce visual words ($\beta$ = `r exclusivity_model_summary$estimate[6]`, *p* `r printp(exclusivity_model_summary$p.value[6],add_equals = TRUE)`). Finally, we again observed a three-way interaction, here between modality, perceptual exclusivity, and group, such that for the sighted group, words that were more unimodal were more likely to be produced for both visual and non-visual words. By contrast, for the blind group, non-visual words that were more unimodal were more likely to be produced, but visual words that were more unimodal were *less* likely to be produced ($\beta$ = `r exclusivity_model_summary$estimate[8]`, *p* `r printp(exclusivity_model_summary$p.value[8],add_equals = TRUE)`).

```{r excl-table}

modelsummary::msummary(
  list("Multimodalness * Modality * Group" = exclusivity_model),
  estimate = "{estimate} [{conf.low}, {conf.high}]",
  statistic = "{printp(p.value)}{stars}",
  stars = c('*' = .05, '**' = .01, '***' = .001),
  fmt = list(
    "estimate" = 2,
    conf.low = 2,
    conf.high = 2,
    "fmt" = NULL
  ),
  shape = term ~ model + statistic,
  coef_rename = c(
    'visualornotvisual' = 'Modality (visual)',
    'Exclusivity.perceptual' = 'Perceptual Exclusivity',
    'groupBlind' = 'Group (blind)',
    'visualornotvisualExclusivity.perceptual' = 'Modality (visual) × Perceptual Exclusivity',
    'visualornotvisualgroupBlind'  = 'Modality (visual) × Group (blind)',
    'Exclusivity.perceptualgroupBlind'  = 'Perceptual Exclusivity × Group (blind)',
    'visualornotvisualExclusivity.perceptualgroupBlind' = 'Modality (visual) × Perceptual Exclusivity × Group (blind)'
  ),
  gof_map = NA,
  output = "data.frame"
) %>%
  select(-1) %>%
  slice(1:(n() - 2))%>%
  kableExtra::kable(
    col.names = c("Variable", "Beta [95% CI]",
                  "p value"),
    caption = 'Logistic regression estimates for the perceptual exclusivity model (see formula in main text). Reference level for Modality is non-visual, and reference level for Group is sighted. Parentheticals indicate what is being compared to reference level.'
  ) %>%
  kableExtra::kable_classic(full_width = FALSE) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position")
```


# Discussion
<!--905 words in discussion 12/21-->

This study compared the early vocabularies of blind and sighted children to better understand the influence of vision on acquiring a lexicon. We found that while blind children in our sample showed vocabulary delays, there were remarkable similarities between the vocabulary composition of blind and sighted children. These results suggest that visual perception facilitates word learning, but does not determine the content of early vocabulary. We further found that the likelihood of word production was predicted by children's access to words through one vs. multiple modalities. 

While the absence of vision does seem to result in vocabulary delays for most children (in our sample, roughly half a year delay on average, with ~20% of blind children ahead of the 50th percentile of sighted children), the exact mechanism by which vision influences vocabulary growth remains unclear. Referential transparency alone seems unlikely: when blind children learn words, they learn a similar number of "visual" words as sighted children. Future work measuring social, motor, and cognitive development alongside vocabulary in blind children may illuminate skills that support word learning. Differences in language input to blind children could also explain the wide variability in language outcomes. By hypothesis, associations between language input and vocabulary development might even be stronger in blind children, given that language may be blind children's source of "visual" information about the world [@campbell2022a]. 

While we only included participants without diganosed cognitive or developmental delays, some participants had vocabulary sizes that fell on the extremes of the distribution; this might indicate undiagnosed cognitive challenges. Given that many early childhood cognitive assessments are not accessible for children with visual impairments (e.g., WPPSI-IV, DAS-II; Bayley), monitoring productive vocabulary growth could provide insight into blind children's cognitive development.

While evidence from blind adults and older children suggests that language skills improve [@roder2003; @loiotile2020; @landau1985], we did not see evidence that vocabulary delays lessen in our age group. In fact, older children in our sample have larger delays. This could be a floor effect: the *possible* size of the delay increases over time, such that 12-month-olds cannot be 18 months delayed, but 30-month-olds can. That said, if blind children, after an initial delay, learn words at the same rate as the sighted peers  we would expect to see a constant delay; we saw an increasing one. This bumps the question downstream: if blind children eventually catch up to sighted peers, when and how does this happen?

One possibility is that blind children initially struggle with word learning. The first words in blind children's vocabulary might be hard-earned. Vision might provide an easier or more efficient way for sighted children to connect referents to objects in their environment. Perhaps after blind children build their initial lexicon, they can leverage linguistic structure more effectively, through processes like syntactic bootstrapping [e.g., @babineau2021]. Evaluating this hypothesis awaits further work.

Turning to vocabulary *content*, blind and sighted children's lexicons were overwhelmingly similar: they were characterized by noun dominance, short, concrete, physically interactive words, and common topics [@frank2021]. Summarizing, blind children learn largely the same set of early words as sighted children. Perhaps surprisingly, the vocabularies of both sighted and blind children are dominated by "visual" words. However, the bulk of the words on the CDI [and the English language, @winter2018] are rated as primarily visual. 

That said, we found that learnability of visual words differed based on words' finer-grained perceptual properties. For blind children, higher perceptual exclusivity (less multimodality) predicted *lower* likelihood of production for visual words (but not non-visual words). For sighted children, perceptual exclusivity did not effect production of either word type. Relatedly, for blind children, higher perceptual strength ratings predicted greater likelihood of word production for non-visual words, but lacked this strong relationship for visual words. Constrastingly, in sighted children, higher perceptual strength predicted greater production likelihood of all words. These exploratory findings suggest that visual words like *light* (highly visual and unidimensional), are less likely to be produced by blind children relative to words that can be perceived through other modalities (e.g. *table*). 

As a relatively large-scale study of language development in young blind children, these results are clinically relevant. Chiefly, blind children are at risk of language delays and may benefit from early intervention communication support. While initial delays may resolve [@brambring2007], providing young blind and their caregivers with tools to communicate better may reduce children's frustration in toddlerhood [@manning2019].

It is worth noting that by design, this study does not capture the full linguistic or diagnostic variability of the blind population. We constrained the sample to young monolingual English-speaking blind children with no more than minimal light perception and no cognitive, developmental, or auditory diagnoses. In reality, the population of children with visual impairment encompasses a broad range of perceptual abilities, language backgrounds, and life experiences. Future work could investigate whether these results generalize to more diverse samples or whether variability in language background or diagnosis contributes to differences in vocabulary outcomes.

Many questions remain regarding how vision interacts with children's social and cognitive skills to form the lexicon. What do blind children's early representations of visual words entail? Is the lexicon organized similarly? How do blind children extract visual information from language input to learn more about both language and their environment? Future work on language development in blind children capturing a more holistic view of blind children's skills and environments is needed to further our understand of how perception and language input interact to support children's learning.

# References